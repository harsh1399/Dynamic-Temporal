{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01accc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7684fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall regex -y\n",
    "# !pip install regex==2022.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edadb696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.30M/6.30M [00:00<00:00, 14.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Basic Imports\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "import xml\n",
    "import json\n",
    "from json2html import *\n",
    "\n",
    "#Web Scraping\n",
    "from mwparserfromhell import parse\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as BraveService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.utils import ChromeType\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver_path = \"chromedriver.exe\"\n",
    "\n",
    "# Define Brave path\n",
    "brave_path = \"C:/Program Files/BraveSoftware/Brave-Browser/Application/brave.exe\"\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = brave_path\n",
    "\n",
    "# Create new automated instance of Brave\n",
    "driver = webdriver.Chrome(service=BraveService(ChromeDriverManager(chrome_type=ChromeType.BRAVE).install()),options = options)\n",
    "# titles = ['International_Space_Station']\n",
    "\n",
    "\n",
    "# \n",
    "# Beezie_Madden\n",
    "# McLain_Ward\n",
    "# Rodrigo_Pessoa\n",
    "# Michael_Jung\n",
    "# Laura_Kraut\n",
    "# Nick_Skelton\n",
    "# Ingrid_Klimke\n",
    "# Kent_Farrington\n",
    "# Ludger_Beerbaum\n",
    "# Mary_King\n",
    "# Mark_Todd\n",
    "# William_Fox-Pitt\n",
    "# Charlotte_Casiraghi\n",
    "# Georgina_Bloomberg\n",
    "# Edwina_Tops-Alexander\n",
    "# Jessica_Springsteen\n",
    "# Zara_Tindall\n",
    "# 'Charlotte_Dujardin', 'Beezie_Madden', 'Jessica_von_Bredow-Werndl' 'Steffen_Peters', 'Sabine_Schut-Kery'\n",
    "# 'Tiger_Woods', 'Jon_Rahm', 'Rory_McIlroy', 'Justin_Thomas', 'Scottie_Scheffler', 'Collin_Morikawa'\n",
    "# 'Maxim_Mikhaylov_(volleyball)', 'Osmany_Juantorena', 'Sergey_Tetyukhin', 'Wallace_de_Souza', 'Bruno_Rezende'\n",
    "# 'Michael_Phelps', 'Dara_Torres', 'Caeleb_Dressel', 'Katie_Ledecky', 'Sun_Yang'\n",
    "# Viswanathan_Anand, Ding_Liren, Ian_Nepomniachtchi, Alireza_Firouzja, Wesley_So\n",
    "# 'Fan_Zhendong', 'Ma_Long', 'Hugo_Calderano', 'Tomokazu_Harimoto', 'Dimitrij_Ovtcharov', 'Timo_Boll'\n",
    "#'P._V._Sindhu', 'Akane_Yamaguchi', 'Chen_Yufei', 'Tai_Tzu-ying', 'An_Se-young','He_Bingjiao', 'Ratchanok_Intanon', 'Wang_Zhiyi'\n",
    "# 'Busanan_Ongbamrungphan', 'Han_Yue', 'Pornpawee_Chochuwong', 'Nozomi_Okuhara', 'Michelle_Li'\n",
    "# ,'Nicol_David','Natalie_Grainger','Linda_Elriani', 'Natalie_Grinham', 'Rachael_Grinham' , Ali_Farag, 'Diego_Elías', 'Tarek_Momen', 'Karim_Abdel_Gawad'\n",
    "# 'James_Willstrop', 'Nick_Matthew', 'Ramy_Ashour', 'Grégory_Gaultier', 'Karim_Darwish_(squash)', 'Amr_Shabana', 'Lee_Beachill'\n",
    "# 'Nouran_Gohar', 'Nour_El_Sherbini', 'Joelle_King', 'Nour_El_Tayeb', 'Sarah-Jane_Perry', 'Laura_Massaro', 'Raneem_El_Weleily'\n",
    "# links = []\n",
    "# for page_title in titles:\n",
    "#     history_page = f\"https://en.wikipedia.org/w/index.php?title={page_title}&action=history\"\n",
    "#     driver.get(history_page)\n",
    "#     inter_links = driver.find_elements(By.PARTIAL_LINK_TEXT,\", \")\n",
    "#     for link in inter_links:\n",
    "#         links.append(link.get_attribute('href')+'&action=raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89f61154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def remove_html_spaces(text):\n",
    "    if \"&nbsp;\" in text:\n",
    "        return re.sub(\"&nbsp;\", ' ', text)\n",
    "    else:\n",
    "        return re.sub(\"&nbsp\", ' ', text)\n",
    "def replace_br(text):\n",
    "    if '<br/>' in text:\n",
    "        return re.sub('\\<br\\/\\>', ', ', text)\n",
    "    elif '<br>' in text:\n",
    "        return re.sub('\\<br\\>', ', ', text)\n",
    "    return text\n",
    "def replace_newlines(text):\n",
    "    return re.sub(\"\\n\", '<>', text)\n",
    "def replace_newlines_tabs(text):\n",
    "    return re.sub(\"\\n\\|\", '\\n||', text)\n",
    "def replace_tabs(text):\n",
    "    return re.sub(\" \\| \", 'ZXC^', text)\n",
    "def replace_tabs_alt(text):\n",
    "    return re.sub(\"\\|\", 'ZXC^', text)\n",
    "def replace_stars(text):\n",
    "    return re.sub(\"\\*\", 'ZXC^', text)\n",
    "def replace_special(text):\n",
    "    return re.sub(\"<>\", ' ', text)\n",
    "def remove_comments(text):\n",
    "    return re.sub('<!--.*?-->','',text)\n",
    "def remove_braces(text):\n",
    "    text = re.sub('{{','',text)\n",
    "    return re.sub('}}','',text)\n",
    "def remove_html(text):\n",
    "    return re.sub('(?<=\\<)(.*?)(?=\\>)','',text)\n",
    "def remove_refs(text):\n",
    "    return re.sub('(?<=\\<ref\\>)(.*?)(?=\\<\\/ref\\>)','',text)\n",
    "def remove_pixel_info(text):\n",
    "    return re.sub(r'\\d+px', '', text)\n",
    "def extract_text_between_braces(string):\n",
    "    return re.findall(r'\\[\\[([^\\[\\]]+)\\]\\]', string)\n",
    "def extract_text_between_curly_braces(string):\n",
    "    return re.findall(r'{{(.*?)}}', string)\n",
    "\n",
    "def clean(text):\n",
    "    # remove html tags\n",
    "    result = remove_refs(text)\n",
    "    result = replace_br(result)\n",
    "    result = remove_pixel_info(result)\n",
    "    result = remove_html_spaces(result)\n",
    "    result = remove_html(result) \n",
    "    result = replace_special(result)\n",
    "    lst = extract_text_between_braces(result)\n",
    "    lst_alt = []\n",
    "    for ele in lst:\n",
    "        if '|' in ele:\n",
    "            result = result.replace(ele, ele.split('|')[1])\n",
    "    lst = extract_text_between_curly_braces(result)\n",
    "    lst_alt = []\n",
    "    for ele in lst:\n",
    "        if ('|' in ele) and ('hlist' not in ele) and ('birth' not in ele):\n",
    "            result = result.replace(ele, ele.split('|')[1])\n",
    "    result = re.sub('[\\[\\]]+','',result) # remove [[around words]]\n",
    "    return result\n",
    "\n",
    "def post_clean(text):\n",
    "    return remove_braces(tab_sep_alt(text.strip()))\n",
    "#     return remove_braces(text.strip())\n",
    "\n",
    "def clean_micro(text):\n",
    "    text = text.strip()\n",
    "    if(re.search(\"(?<={{)(.*?)(?=\\|)\",text)):\n",
    "        text = text[re.search(\"(?<={{)(.*?)(?=\\|)\",text).end()+1:-2]\n",
    "    return text\n",
    "\n",
    "def extract_curly(text,phrase):\n",
    "    text2 = text[re.search(phrase,text).start()+2:]\n",
    "    i=2\n",
    "    temp = ''\n",
    "    for char in text2:\n",
    "        if (i==0):\n",
    "            break\n",
    "        temp += char\n",
    "        if char=='{':\n",
    "            i = i+1\n",
    "        elif char=='}':\n",
    "            i = i-1\n",
    "    return re.sub(\"{{\"+temp,'',text)\n",
    "\n",
    "def tab_sep_alt(text):\n",
    "    if(re.search('\\S\\|\\S',text)):\n",
    "        text = text[re.search('\\S\\|\\S',text).start()+2:]\n",
    "    return text\n",
    "\n",
    "def clean_square(text):\n",
    "    \"\"\" Removes unwanted characters from the text \"\"\"\n",
    "    return text.strip().strip(\"[]\")\n",
    "\n",
    "def modify(json_dict,key):\n",
    "    # removing curly brace part for specific cases\n",
    "    try:\n",
    "        temps = [\"{{ctitle\",\"{{cite\",\"{{Cite\"]\n",
    "        for temp in temps:\n",
    "            while(re.search(temp,json_dict[key])):\n",
    "                json_dict[key] = extract_curly(json_dict[key],temp)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(re.search(\"{{flatlist\",json_dict[key]) or re.search(\"{{flat list\",json_dict[key]) or re.search(\"{{plainlist\",json_dict[key]) or ('*' in json_dict[key])):\n",
    "            if 'top score' not in key:\n",
    "                json_dict[key] = replace_stars(json_dict[key]+'*')\n",
    "                json_dict[key] = [remove_braces(s.strip()) for s in re.findall('\\^(.*?)ZXC',json_dict[key])]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(re.search(\"{{unbulleted\",json_dict[key])): #not clear yet\n",
    "            try:\n",
    "                json_dict[key] = [re.sub('}}','',ele) for ele in json_dict[key].split(\"|{{\")[1:]]\n",
    "            except:\n",
    "                json_dict[key] = json_dict[key].split(\"|\")[1:]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(re.search(\"{{hlist\",json_dict[key])):\n",
    "            json_dict[key] = replace_tabs_alt(json_dict[key]+'|')\n",
    "            json_dict[key] =  [remove_braces(s.strip()) for s in re.findall('\\^(.*?)ZXC',json_dict[key])]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(re.search(\"(?<={{)(.*?)(?=\\|)\",json_dict[key])):\n",
    "            json_dict[key] = json_dict[key][:re.search(\"(?<={{)(.*?)(?=\\|)\",json_dict[key]).start()-2]+json_dict[key][re.search(\"(?<={{)(.*?)(?=\\|)\",json_dict[key]).end()+1:-2]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595fb62",
   "metadata": {},
   "source": [
    "Write Multiple Script Variations (Pruned vs Unpruned and Full key vs Interesting Keys and Clean vs general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ecaaf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'station': 'International Space Station',\n",
       " 'COSPAR_ID': '1998-067A',\n",
       " 'SATCAT': '25544',\n",
       " 'sign': \"''Alpha'', ''Station''\",\n",
       " 'crew': 'Fully crewed: 7 ',\n",
       " 'launch': '1998',\n",
       " 'launch_pad': ['nowrap', 'Kennedy, LC-39 and CCSFS, SLC-40'],\n",
       " 'mass': '450000',\n",
       " 'title': 'ISS: International Space Station ',\n",
       " 'length': '358 (Overall length), 310 (truss length)  last=Garcia ',\n",
       " 'width': '239 (solar array length)',\n",
       " 'volume': '35491',\n",
       " 'pressure': '101.3 79% nitrogen, 21% oxygen',\n",
       " 'perigee': '413 AMSL last=Peat ',\n",
       " 'apogee': '422 AMSL',\n",
       " 'inclination': '51.64°',\n",
       " 'speed': '7.66',\n",
       " 'period': '92.9 minutes',\n",
       " 'orbits_day': '15.49',\n",
       " 'in_orbit': '20 November 1998 06:40 (TODAY)',\n",
       " 'occupied': '2 November 2000 09:21 (TODAY)',\n",
       " 'orbits': '133,312  2022',\n",
       " 'decay': '2 km/month',\n",
       " 'orbit_epoch': '12 October 2022 14:25:10  last=Holman ',\n",
       " 'apsis': 'gee',\n",
       " 'as_of': '22 December 2022 (unless noted otherwise)'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpath = '/html/body/pre'\n",
    "# for link in links:\n",
    "link = links[0]\n",
    "driver.get(link)\n",
    "json_dict = dict()\n",
    "infobox = remove_comments(driver.find_element(By.XPATH,xpath).text) # No real assumptions here\n",
    "# for word in space_words:\n",
    "#     if (len(infobox.split(word)) > 1):\n",
    "#         infobox = infobox.replace(word, ' ' + word)\n",
    "temp = replace_special(re.findall('(?<=\\{\\{Infobox)(.*)',replace_newlines(infobox))[0]) #Ok\n",
    "# Figuring out where }} ends to mark end of infobox\n",
    "i=2\n",
    "infobox2 = ''\n",
    "for char in temp:\n",
    "    if (i==0):\n",
    "        break\n",
    "    infobox2 = infobox2 + char\n",
    "    if char=='{':\n",
    "        i = i+1\n",
    "    elif char=='}':\n",
    "        i = i-1\n",
    "raw_dict = dict()\n",
    "raw_dict_inter = dict()\n",
    "json_dict = dict()\n",
    "column_list = []\n",
    "global_lst = []\n",
    "championship_years = {}\n",
    "birth_date = ''\n",
    "letter = ''\n",
    "try:\n",
    "    infobox2 = infobox2.split('medaltemplates')[0] + 'medaltemplates' + infobox2.split('medaltemplates')[1].replace(' | ','|')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    infobox2 = infobox2.split('medal_templates')[0] + 'medal_templates' + infobox2.split('medal_templates')[1].replace(' | ','|')\n",
    "except:\n",
    "    pass\n",
    "for key_value in re.findall('\\^(.*?)ZXC',replace_tabs(infobox2+' | ')):\n",
    "    try:    \n",
    "        key = key_value.split('=')[0]\n",
    "        value = '='.join(key_value.split('=')[1:])\n",
    "        if value.strip() == '':\n",
    "            key = key_value.split(': ')[0]\n",
    "            value = ': '.join(key_value.split(':')[1:])\n",
    "        if value.strip() == '':\n",
    "            key = key_value.split('=')[0]\n",
    "            value = '='.join(key_value.split('=')[1:])\n",
    "        # Do i need these strips??\n",
    "        key = key.strip()\n",
    "        raw_dict[key] = value\n",
    "        raw_dict_inter[key] = clean(value)\n",
    "        if (\"medal\" in key) and (\"show\" not in key):\n",
    "#             value = infobox2.split('medaltemplates =')[1]\n",
    "            wikicode = parse(value)\n",
    "            medal_templates = wikicode.filter_templates()\n",
    "            for template in medal_templates:\n",
    "                try:\n",
    "                    if template.name.matches(\"MedalSport\"):\n",
    "                        global_lst.append(\"Sport: \"+clean(template.get(1).value.strip()))\n",
    "                    elif template.name.matches(\"MedalCountry\"):\n",
    "                        global_lst.append(\"Country: \"+clean(template.get(1).value.strip()))\n",
    "                    elif template.name.matches(\"MedalCount\"):\n",
    "                        global_lst.append(\"Competition: \"+clean(template.get(1).value.strip()))\n",
    "                        global_lst.append(\"Gold Medal: \"+clean(template.get(2).value.strip()))\n",
    "                        global_lst.append(\"Silver Medal: \"+clean(template.get(3).value.strip()))\n",
    "                        global_lst.append(\"Bronze Medal: \"+clean(template.get(4).value.strip()))\n",
    "                        global_lst.append(\"Competition: \"+clean(template.get(5).value.strip()))\n",
    "                        global_lst.append(\"Gold Medal: \"+clean(template.get(6).value.strip()))\n",
    "                        global_lst.append(\"Silver Medal: \"+clean(template.get(7).value.strip()))\n",
    "                        global_lst.append(\"Bronze Medal: \"+clean(template.get(8).value.strip()))\n",
    "                        global_lst.append(\"Competition: \"+clean(template.get(9).value.strip()))\n",
    "                        global_lst.append(\"Gold Medal: \"+clean(template.get(10).value.strip()))\n",
    "                        global_lst.append(\"Silver Medal: \"+clean(template.get(11).value.strip()))\n",
    "                        global_lst.append(\"Bronze Medal: \"+clean(template.get(12).value.strip()))\n",
    "                    elif template.name.matches(\"MedalCompetition\"):\n",
    "                        competition = clean(template.get(1).value.strip())\n",
    "                        global_lst.append(\"Competition: \"+competition)\n",
    "                    elif template.name.matches(\"MedalGold\"):\n",
    "                        try:\n",
    "                            competition = clean(template.get(1).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            year_event = clean(template.get(2).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            event = clean(template.get(3).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        string = 'Gold Medal: '\n",
    "                        try:\n",
    "                            string = string + competition\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + year_event\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + event\n",
    "                        except:\n",
    "                            pass\n",
    "                        global_lst.append(string)\n",
    "                    elif template.name.matches(\"MedalSilver\"):\n",
    "                        try:\n",
    "                            competition = clean(template.get(1).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            year_event = clean(template.get(2).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            event = clean(template.get(3).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        string = 'Silver Medal: '\n",
    "                        try:\n",
    "                            string = string + competition\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + year_event\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + event\n",
    "                        except:\n",
    "                            pass\n",
    "                        global_lst.append(string)\n",
    "                    elif template.name.matches(\"MedalBronze\"):\n",
    "                        try:\n",
    "                            competition = clean(template.get(1).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            year_event = clean(template.get(2).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            event = clean(template.get(3).value.strip())\n",
    "                        except:\n",
    "                            pass\n",
    "                        string = 'Bronze Medal: '\n",
    "                        try:\n",
    "                            string = string + competition\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + year_event\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            string = string + ' ' + event\n",
    "                        except:\n",
    "                            pass\n",
    "                        global_lst.append(string)\n",
    "                except:\n",
    "                    pass\n",
    "            break\n",
    "        elif key == 'WorldOpenresult':\n",
    "            match = re.search(\"^[a-zA-Z]\", value)\n",
    "            if match:\n",
    "                letter = match\n",
    "            parsed_code = parse(value)\n",
    "            links = parsed_code.filter_wikilinks()\n",
    "            for link in links:\n",
    "                year = link.text.strip()\n",
    "                championship_years[year] = link.title.strip()\n",
    "                \n",
    "        elif key == 'birth_date':\n",
    "            parsed_code = parse(value)\n",
    "            date_template = parsed_code.filter_templates()[0]\n",
    "            try:\n",
    "                birth_date = birth_date + date_template.get(1).value.strip() + '-' \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                birth_date = birth_date + date_template.get(2).value.strip() + '-' \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                birth_date = birth_date + date_template.get(3).value.strip() + '-'\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                birth_date = birth_date + date_template.get(4).value.strip()\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            json_dict[key] = clean(value)\n",
    "            \n",
    "        \n",
    "#         # Birth Date and Age\n",
    "#         if key == 'birth_date' or key == 'death_date':\n",
    "#             json_dict[key] = json_dict[key][:re.search(\"(?<={{)(.*?)(?=\\|)\",json_dict[key]).start()-2] \n",
    "#             + json_dict[key][re.search(\"(?<={{)(.*?)(?=\\|)\",json_dict[key]).end()+1:-2]\n",
    "#             if 'df=yes' in json_dict[key]:\n",
    "#                 json_dict[key] = re.sub('\\|df=yes','',json_dict[key]).strip()\n",
    "#             if 'df=y' in text:\n",
    "#                 json_dict[key] = re.sub('\\|df=y','',json_dict[key]).strip()\n",
    "\n",
    "#         # Birth Place\n",
    "#         if key == 'birth_place':\n",
    "#             if 'full_name' in json_dict[key]:\n",
    "#                 json_dict[key] = re.sub('\\|full_name =','',json_dict[key]).strip()\n",
    "                \n",
    "#         # Bowling\n",
    "#         if key == 'bowling':\n",
    "#             json_dict[key] = json_dict[key].strip()\n",
    "#             json_dict[key] = json_dict[key][:json_dict[key].rindex(' '):] + ' ' + tab_sep_alt(json_dict[key])\n",
    "        \n",
    "        # Nickname and height\n",
    "        if key in ['nickname', 'height', 'birth_place', 'weight', 'trainer', 'names', 'billed',\n",
    "                  'debut', 'retired', 'campus_size', 'students', 'endowment', 'vice_chancellor',\n",
    "                   'religious_affiliation', 'academic_affiliations', 'president']:\n",
    "            json_dict[key] = re.sub('url(.*)', '', json_dict[key])\n",
    "            json_dict[key] = re.sub('https(.*)', '', json_dict[key])\n",
    "            json_dict[key] = re.sub('title(.*)', '', json_dict[key])\n",
    "        \n",
    "        # Name and fullname\n",
    "        if key in ['name', 'full_name']:\n",
    "            json_dict[key] = re.sub(\"post-nominals\",\"\",json_dict[key])\n",
    "        \n",
    "        if key in ['strokes']:\n",
    "            json_dict[key] = re.sub('date(.*)', '', json_dict[key])\n",
    "        \n",
    "#         # Top Score\n",
    "#         if 'top score' in key and '*' in json_dict[key] :\n",
    "#             if (json_dict[key][:-9].strip() != ''):\n",
    "#                 json_dict[key] = json_dict[key][:-9].strip()\n",
    "            \n",
    "#         #Website\n",
    "#         if key == 'website':\n",
    "#             json_dict[key] = re.sub('(?<=\\}\\}\\|).*','', json_dict[key])\n",
    "        \n",
    "        raw_dict_inter_inter = json_dict.copy()\n",
    "        json_dict[key] = re.sub('url(.*)', '', json_dict[key])\n",
    "        modify(json_dict, key)\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# Post Modification Cleaning\n",
    "for key in json_dict:\n",
    "    if type(json_dict[key]) is str:\n",
    "        json_dict[key] = post_clean(json_dict[key])\n",
    "    elif type(json_dict[key]) is list:\n",
    "        json_dict[key] = [post_clean(a) for a in json_dict[key]]\n",
    "        \n",
    "        \n",
    "# Removing empty slots\n",
    "remove = []\n",
    "for key in json_dict.keys():\n",
    "    try:\n",
    "        if(json_dict[key].strip() == ''):\n",
    "            remove.append(key)\n",
    "    except:\n",
    "        pass\n",
    "for key in remove:\n",
    "    json_dict.pop(key)\n",
    "\n",
    "                \n",
    "squash_redundant = ['image', 'alt', 'caption', 'show-medals', 'module', 'updated', 'url', 'work', \n",
    "            'child', 'image_size', 'pb', 'signature', 'signature_alt', 'module2', 'reach_footnote', 'weight_footnote',\n",
    "            'height_footnote', 'footnotes', 'show-medals', \"logo\" \n",
    "\"logo_size\" ,\n",
    "\"logo_upright\", \n",
    "\"logo_alt\" ,\n",
    "\"embedded\",\n",
    "\"pushpin_map\", \n",
    "\"pushpin_label_position\" ,\n",
    "\"map_size\" ,\n",
    "\"pushpin_map_caption\" ,\n",
    "\"footnotes\" ,\n",
    "\"image\" ,\n",
    "\"image_upright\", \n",
    "\"image_alt\", \n",
    "\"caption\" ,\n",
    "\"native_name_lang\",\n",
    "\"head_label\",\n",
    "\"logo\" ,\n",
    "\"logo_size\" ,\n",
    "\"logo_upright\", \n",
    "\"logo_alt\" ,\n",
    "\"free_label\",\n",
    "\"free_label2\",\n",
    "\"free\",\n",
    "\"free2\",\n",
    "\"sports_free_label\",\n",
    "\"sports_free_label2\",\n",
    "\"sports_free_label3\",\n",
    "\"sports_free\",\n",
    "\"sports_free2\",\n",
    "\"sports_free3\",\n",
    "\"station_image\", \"station_image_alt\", \"configuration_image\", \"configuration_image_alt\", \"configuration_alt\", \"caption\",\n",
    "\"configuration_caption\", \"insignia\", \"insignia_caption\", \"station_image_caption\"]\n",
    "\n",
    "for key in squash_redundant:\n",
    "    try:\n",
    "        json_dict.pop(key)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# prev_key = ''\n",
    "# for key in sorted(json_dict.keys()):\n",
    "#     try:\n",
    "#         if((key[:-1]==prev_key[:-1]) and (prev_key[-1] in ['','1','2','3','4','5','6','7','8''9'])):\n",
    "#             if ((type(json_dict[prev_key]) is str) and (type(json_dict[key]) is str)):\n",
    "#                 json_dict[prev_key] = {column_list[int(prev_key[-1].strip())-1]:json_dict[prev_key],\n",
    "#                                        column_list[int(key[-1].strip())-1]:json_dict[key]}\n",
    "#             elif ((type(json_dict[prev_key]) is dict) and (type(json_dict[key]) is str)):\n",
    "#                 json_dict[prev_key][column_list[int(key[-1].strip())-1]] = json_dict[key]\n",
    "#             elif ((type(json_dict[prev_key]) is str) and (type(json_dict[key]) is dict)):\n",
    "#                 {column_list[int(prev_key[-1].strip())-1]:json_dict[prev_key]}[key[-1]] = json_dict[key]\n",
    "#             elif ((type(json_dict[prev_key]) is dict) and (type(json_dict[key]) is dict)):\n",
    "#                 json_dict[prev_key].extend(json_dict[key])\n",
    "#             json_dict.pop(key)\n",
    "#         else:\n",
    "#             prev_key = key\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# draftyear           = \n",
    "# | draftround          = \n",
    "# | draftpick           = \n",
    "# | suppdraftyear       = \n",
    "# | suppdraftround      = \n",
    "# | cfldraftyear        = \n",
    "# | cfldraftround       = \n",
    "# | cfldraftpick        = \n",
    "# | afldraftyear        = \n",
    "# | afldraftround       = \n",
    "# | afldraftpick        = \n",
    "# | undraftedyear       = \n",
    "# | expansiondraftyear  = \n",
    "# | expansiondraftround = \n",
    "# | expansiondraftpick  = \n",
    "\n",
    "#nfldraft\n",
    "# nfl_lst = []\n",
    "# for key in json_dict.keys():\n",
    "#     if key in ['draftyear', 'draftround', 'draftpick']:\n",
    "#         nfl_lst.append(key)\n",
    "# lst = {}\n",
    "# for key in nfl_lst:\n",
    "#     lst[key[5:]] = json_dict[key]\n",
    "#     del json_dict[key]\n",
    "# if lst:\n",
    "#     json_dict['nfl_draft'] = lst\n",
    "\n",
    "#suppdraft\n",
    "# supp_lst = []\n",
    "# for key in json_dict.keys():\n",
    "#     if 'suppdraft' in key:\n",
    "#         supp_lst.append(key)\n",
    "# lst = {}\n",
    "# for key in supp_lst:\n",
    "#     lst[key[9:]] = json_dict[key]\n",
    "#     del json_dict[key]\n",
    "# if lst:\n",
    "#     json_dict['supplemental_draft'] = lst\n",
    "\n",
    "# #afldraft\n",
    "# afl_lst = []\n",
    "# for key in json_dict.keys():\n",
    "#     if 'afldraft' in key:\n",
    "#         afl_lst.append(key)\n",
    "# lst = {}\n",
    "# for key in afl_lst:\n",
    "#     lst[key[8:]] = json_dict[key]\n",
    "#     del json_dict[key]\n",
    "# if lst:\n",
    "#     json_dict['afl_draft'] = lst\n",
    "    \n",
    "#statleague\n",
    "# stats = []\n",
    "# for key in json_dict.keys():\n",
    "#     for i in range(1,18):\n",
    "#         if (f'statlabel{i}' in json_dict.keys() and f'statvalue{i}' in json_dict.keys()):\n",
    "#             stats.append(i)\n",
    "# stats = list(set(stats))\n",
    "# lst = {}\n",
    "# for num in stats:\n",
    "#     lst[json_dict[f'statlabel{num}']] = json_dict[f'statvalue{num}']\n",
    "#     del json_dict[f'statlabel{num}']\n",
    "#     del json_dict[f'statvalue{num}']\n",
    "# if lst:\n",
    "#     try:\n",
    "#         json_dict[json_dict['statleague']] = lst\n",
    "#         del json_dict['statleague']\n",
    "#     except:\n",
    "#         json_dict['stats'] = lst\n",
    "    \n",
    "# #nationalteams\n",
    "nt_lst = []    \n",
    "for i in range(1,18):\n",
    "    if f'nationalyears{i}' in json_dict.keys():\n",
    "        nt_lst.append(i)\n",
    "\n",
    "lst = {}\n",
    "for num in nt_lst:\n",
    "    try:\n",
    "        lst[json_dict[f'nationalteam{num}']] = json_dict[f'nationalyears{num}']\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    try:\n",
    "        del json_dict[f'nationalteam{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        del json_dict[f'nationalyears{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if lst:\n",
    "    json_dict['nationalteams'] = lst\n",
    "    \n",
    "# Club Structuring\n",
    "club_lst = []    \n",
    "for i in range(1,18):\n",
    "    if f'years{i}' in json_dict.keys():\n",
    "        club_lst.append(i)\n",
    "\n",
    "lst = {}\n",
    "for num in club_lst:\n",
    "    try:\n",
    "        lst[json_dict[f'team{num}']] = json_dict[f'years{num}']\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    try:\n",
    "        del json_dict[f'team{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        del json_dict[f'years{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if lst:\n",
    "    json_dict['clubs'] = lst\n",
    "    \n",
    "# Club Structuring\n",
    "award_lst = []    \n",
    "for i in range(1,18):\n",
    "    if f'year{i}' in json_dict.keys():\n",
    "        award_lst.append(i)\n",
    "\n",
    "lst = {}\n",
    "for num in award_lst:\n",
    "    try:\n",
    "        lst[json_dict[f'award{num}']] = json_dict[f'year{num}']\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    try:\n",
    "        del json_dict[f'award{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        del json_dict[f'year{num}']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if lst:\n",
    "    json_dict['awards'] = lst\n",
    "\n",
    "    \n",
    "try:\n",
    "    if birth_date:\n",
    "        json_dict['birth_date'] = birth_date[:-1]\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "try:\n",
    "    if global_lst:\n",
    "        json_dict['medaltemplates'] = global_lst\n",
    "    else:\n",
    "        json_dict['medaltemplates'] = raw_dict['medaltemplates']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if championship_years:\n",
    "        json_dict['WorldOpenresult'] = championship_years\n",
    "except:\n",
    "    pass\n",
    "# # try:\n",
    "#     fide_id = int(json_dict['FideID'].strip())\n",
    "#     url = f\"http://ratings.fide.com/card.phtml?event={fide_id}\"\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     try:\n",
    "#         std_rating = re.findall('\\d\\d\\d\\d', soup.find('div',{'class':'profile-top-rating-data profile-top-rating-data_gray'}).text)[0]\n",
    "#         json_dict['std_rating'] = std_rating\n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         rapid_rating = re.findall('\\d\\d\\d\\d', soup.find('div',{'class':'profile-top-rating-data profile-top-rating-data_red'}).text)[0]\n",
    "#         json_dict['rapid_rating'] = rapid_rating\n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         blitz_rating = re.findall('\\d\\d\\d\\d', soup.find('div',{'class':'profile-top-rating-data profile-top-rating-data_blue'}).text)[0]\n",
    "#         json_dict['blitz_rating'] = blitz_rating\n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         ranking = re.findall('\\d', soup.find('div',{'class':'profile-top-info__block__row__data'}).text)[0]\n",
    "#         json_dict['current_ranking'] = ranking\n",
    "#     except:\n",
    "#         try:\n",
    "#             ranking = re.findall('\\d\\d', soup.find('div',{'class':'profile-top-info__block__row__data'}).text)[0]\n",
    "#             json_dict['current_ranking'] = ranking\n",
    "#         except:\n",
    "#             pass\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9870bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971-11-21-\n"
     ]
    }
   ],
   "source": [
    "import mwparserfromhell\n",
    "\n",
    "wikicode = \"{{Birth date and age|df=y|1971|11|21}}\"\n",
    "parsed_code = mwparserfromhell.parse(wikicode)\n",
    "date_template = parsed_code.filter_templates()[0]\n",
    "birth_date = ''\n",
    "try:\n",
    "    birth_date = birth_date + date_template.get(1).value.strip() + '-' \n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    birth_date = birth_date + date_template.get(2).value.strip() + '-' \n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    birth_date = birth_date + date_template.get(3).value.strip() + '-'\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    birth_date = birth_date + date_template.get(4).value.strip()\n",
    "except:\n",
    "    pass\n",
    "print(birth_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "729dbbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{short description|Swiss alpine skier}}\\n{{Use dmy dates|date=September 2022}}\\n{{Infobox alpine ski racer\\n| name          = Maria Walliser\\n| image         = Maria Walliser.png\\n|  image_size    = \\n| caption       = \\n| disciplines   = Speed events, Giant slalom\\n| club          = SC Libingen\\n| birth_date    = {{birth date and age|27 May 1963|df=yes}}\\n| birth_place   = [[Mosnang]], [[Switzerland]]\\n| death_date    = \\n| death_place   = \\n| height        = 1.68 m\\n| wcdebut       = 1983\\n| retired       = 1990\\n| website       = \\n| olympicteams  = 2\\n| olympic medals = 3\\n| olympicgolds  = \\n| worldsteams   = 4\\n| worlds medals  = 4\\n| worldsgolds   = 3\\n| wcseasons     = 8\\n| wcwins        = 25\\n| wcpodiums     = 72\\n| wcoveralls    = 2\\n| wctitles      = 5\\n|show- medals   = yes\\n|med altemplates= \\n{{Medal|Sport|Women\\'s [[alpine skiing]]}}\\n{{Medal|Country|{{SUI}}}} \\n{{MedalCount|total=yes|type=World Cup race podiums\\n| Slalom       | 0 | 0 | 1\\n| Giant slalom | 6 | 5 | 6\\n| Downhill     | 14 | 10 | 13\\n| Super-G      | 3 | 3 | 3\\n| Combined     | 2 | 3 | 3\\n}}\\n{{MedalCompetition | [[Olympic Games]] }}\\n{{MedalSilver | [[1984 Winter Olympics|1984 Sarajevo]] | [[Alpine skiing at the 1984 Winter Olympics – Women\\'s downhill|Downhill]]}}\\n{{MedalBronze | [[1988 Winter Olympics|1988 Calgary]] | [[Alpine skiing at the 1988 Winter Olympics – Women\\'s combined|Alpine Combined]]}}\\n{{MedalBronze | [[1988 Winter Olympics|1988 Calgary]] | [[Alpine skiing at the 1988 Winter Olympics – Women\\'s giant slalom|Giant Slalom]]}}\\n{{MedalCompetition | World Championships }}\\n{{MedalGold | [[Alpine World Ski Championships 1987|1987 Crans-Montana]] | Downhill }}\\n{{MedalGold | [[Alpine World Ski Championships 1987|1987 Crans-Montana]] | Super-G }}\\n{{MedalGold | [[Alpine World Ski Championships 1989|1989 Vail]] | Downhill }}\\n{{MedalBronze | [[Alpine World Ski Championships 1987|1987 Crans-Montana]] | Giant Slalom }}\\n}}\\n\\'\\'\\'Maria Walliser\\'\\'\\' (born 27 May 1963) is a Swiss former [[alpine skiing|alpine skier]].<ref  name=FIS>{{cite web|url=https://www.fis-ski.com/DB/general/athlete-biography.html?sectorcode=AL&listid=&competitorid=65118|title=Maria Walliser profile| website=fis-ski.com|access-date=26 September 2022}}</ref>\\n\\n==Career==\\nWalliser grew up in [[Mosnang]], the daughter of a we althy cattle breeder. She made her World Cup debut in 1980.<ref>{{cite magazine |last=Johnson |first=William Oscar |date=27 January 1988 |title=Smooth as Clockwork |url=https://www.si.com/vault/1988/01/27/117043/alpine-skiing-smooth-as-clockwork-so-strong-are-its-men-and-women-skiers-the-team-from-switzerland-may-come-close-to-a-clean-medal-sweep |magazine=[[Sports Illustrated]] |access-date=10 March 2016}}</ref> Together with her fellow Swiss [[Erika Hess]], [[Michela Figini]] and [[Vreni Schneider]] she dominated female alpine skiing during the 1980s. Among her many successes, she won two overall [[FIS Alpine Ski World Cup|World Cups]] (1986 and 1987). Walliser also won three world titles in 1987 and 1989, as well as three Olympic  medals at [[1988 Winter Olympics|1988 Calgary]] and [[1984 Winter Olympics|1984 Sarajevo]].<ref  name=sr />\\n\\nWalliser  retired in 1990{{fact|date=July 2021}} with a World Cup tally of 72 podium finishes, including 25 victories. In 2000, she became president of \"Die Stiftung Folsäure Offensive Schweiz\", a Swiss he alth organization fighting [[folate deficiency]].<ref  name=sr>{{cite Sports-Reference |url=https://www.sports-reference.com/olympics/athletes/wa/maria-walliser-1.html|archive-url=https://web.archive.org/web/20200417120505/https://www.sports-reference.com/olympics/athletes/wa/maria-walliser-1.html|url-status=dead|archive-date=2020-04-17}}</ref>\\n\\n==World Cup results==\\n===Season titles===\\n* 7 titles – (2 Overall, 2 [[Downhill (ski competition)|DH]], 1 [[Giant Slalom|GS]], 1 [[Alpine skiing combined|AC]], 1 [[Super-G|SG]])\\n{| class=\"wikitable\"  style=\"font-size:95%; text-align:center; border:gray solid 1px; width:30%;\"\\n|- style=\"background:#369; color:white;\"\\n| rowspan=\"22\" style=\"width:1%;\"|[[File:FIS Crystal Globe.svg|150px]]\\n| rowspan=\"2\" style=\"width:10%;\"|\\'\\'\\'Season\\'\\'\\'\\n|- style=\"background:#4180be; color:white;\"\\n| style=\"width:10%;\"|Discipline\\n|-\\n| [[1983–84 FIS Alpine Ski World Cup|1984]] \\n| [[1984 Alpine Skiing World Cup – Women\\'s Downhill|Downhill]]\\n|-\\n| rowspan=\"3\" | [[1986 Alpine Skiing World Cup|1986]] || \\'\\'\\'Overall\\'\\'\\'\\n|-\\n| [[1986 Alpine Skiing World Cup – Women\\'s Downhill|Downhill]]\\n|-\\n| [[1986 Alpine Skiing World Cup – Women\\'s Combined|Combined]]\\n|-\\n| rowspan=\"3\" | [[1987 Alpine Skiing World Cup|1987]] || \\'\\'\\'Overall\\'\\'\\'\\n|-\\n| [[1987 Alpine Skiing World Cup – Women\\'s Super-G|Super-G]]\\n|-\\n| [[1987 Alpine Skiing World Cup – Women\\'s Giant Slalom|Giant Slalom]]\\n|}\\n\\n===Season standings===\\n{| class=\"wikitable\" style=\"text-align:center; width:800px;\" \\n|- style=\"background:#369; color:white;\"\\n| rowspan=\"2\" width=\"4%\" | Season\\n| colspan=\"2\" | Overall\\n| colspan=\"2\" | Downhill\\n| colspan=\"2\" | Super G\\n| colspan=\"2\" | Giant slalom\\n| colspan=\"2\" | Slalom\\n| colspan=\"2\" | Combined\\n|- style=\"background:#369; color:white;\"\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n| width=\"5%\" | <small>Rank</small>\\n| width=\"5%\" | <small>Points</small>\\n|-\\n| align=center| [[Alpine Ski World Cup 1980–81|1981]] || 12. || 112 || 11. || 41 || – || – || 18. || 14 || \\'\\'\\'19.\\'\\'\\' || 22 || 8. || 35\\n|-\\n| align=center| [[Alpine Ski World Cup 1981–82|1982]] || 17. || 75 || 8. || 59 || – || – || 25. || 12 || 32. || 4 || – || –\\n|-\\n| align=center| [[Alpine Ski World Cup 1982–83|1983]] || 5. || 135 || style=\"background-color:#DCE5E5\"|2. || style=\"background-color:#DCE5E5\"|97 || – || – || 10. || 40 || – || – || 18. || 11\\n|-\\n| align=center| [[Alpine Ski World Cup 1983–84|1984]] || 8. || 131 || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|95 || – || – || 18. || 24 || – || – || 8. || 43\\n|-\\n| align=center| [[Alpine Ski World Cup 1984–85|1985]] || style=\"background-color:#FFDAB9\"|3. || style=\"background-color:#FFDAB9\"|197 || style=\"background-color:#DCE5E5\"|2. || style=\"background-color:#DCE5E5\"|81 || – || – || 4. || 87 || 41. || 2 || style=\"background-color:#FFDAB9\"|3. || style=\"background-color:#FFDAB9\"|50\\n|-\\n| align=center| [[Alpine Ski World Cup 1985–86|1986]] || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|287 || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|115 || 10. || 24 || 4. || 76 || 40. || 2 || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|70\\n|-\\n| align=center| [[Alpine Ski World Cup 1986–87|1987]] || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|269 || style=\"background-color:#DCE5E5\"|2. || style=\"background-color:#DCE5E5\"|90 || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|82 || style=\"background-color:#F7F6A8\"|\\'\\'\\'1.\\'\\'\\' || style=\"background-color:#F7F6A8\"|120 || – || – || 4. || 12\\n|-\\n| align=center| [[Alpine Ski World Cup 1987–88|1988]] || 7. || 143 || style=\"background-color:#FFDAB9\"|3. || style=\"background-color:#FFDAB9\"|82 || 24. || 5 || 8. || 40 || – || – || 6. || 16\\n|-\\n| align=center| [[Alpine Ski World Cup 1988–89|1989]] || style=\"background-color:#DCE5E5\"|2. || style=\"background-color:#DCE5E5\"|261 || style=\"background-color:#DCE5E5\"|2. || style=\"background-color:#DCE5E5\"|142 || 6. || 27 || style=\"background-color:#FFDAB9\"|3. || style=\"background-color:#FFDAB9\"|87 || – || – || 18. || 5\\n|-\\n| align=center| [[Alpine Ski World Cup 1989/90|1990]] || 4. || 227 || 5. || 99 || 5. || 56 || 6. || 55 || – || – || 7. || 17\\n|}\\n\\n===Race victories===\\n25 race victories (14 [[downhill (ski competition)|downhill]], 3 [[super G]], 6 [[giant slalom skiing|giant slalom]], 2 [[alpine skiing combined|combined]])\\n\\n{| class=\"wikitable\"  style=\"font-size:100%; text-align:left; border:gray solid 1px; width:40%;\"\\n|- style=\"background-color:#369; color:white;\"\\n| align=center|Date\\n| align=center|Location\\n| align=center|Discipline\\n|-\\n| 21 January 1983 || {{flagicon|FRA}}  [[Megève]] || Downhill\\n|-\\n| 5 February 1983 || {{flagicon|YUG}} [[Sarajevo]] || Downhill\\n|-\\n| 8 December 1983 || {{flagicon|FRA}}  [[Val-d\\'Isère]] || Downhill\\n|-\\n| 21 January 1984 || {{flagicon|SUI}} [[Verbier]] || Downhill\\n|-\\n| 8 March 1985 || {{flagicon|Canada}} [[Sunshine Village]] || Downhill\\n|-\\n| 11 January 1986 || {{flagicon|AUT}} [[Bad Gastein]] || Downhill\\n|-\\n| 12 January 1986 || {{flagicon|AUT}} Bad Gastein || Combined\\n|-\\n| 5 February 1986 || {{flagicon|ITA}} {{ill|Val Zoldana|it|Val di Zoldo}} || Giant Slalom\\n|-\\n| 1 March 1986 || {{flagicon|Japan}}  [[Furano Ski Resort|Furano]] || Downhill\\n|-\\n| 8 March 1986 || {{flagicon|CAN}}  Sunshine Village || Downhill\\n|-\\n| 9 March 1986 || {{flagicon|CAN}}  Sunshine Village || Combined\\n|-\\n| 14 December 1986 || {{flagicon|FRA}}  Val d\\'Isère || Super-G\\n|-\\n| 20 December 1986 || {{flagicon|ITA}}  Val Zoldana || Giant Slalom\\n|-\\n| 6 January 1987 || {{flagicon|AUT}}  [[Saalbach-Hinterglemm]] || Super-G\\n|-\\n| 18 January 1987 || {{flagicon|GER}} [[Bischofswiesen]] || Giant Slalom\\n|-\\n| 27 February 1987 || {{flagicon|GER}} [[Zwiesel]] || Giant Slalom\\n|-\\n| 15 March 1987 || {{flagicon|USA}} [[Vail, Colorado|Vail]]  || Super-G\\n|-\\n| 22 March 1987 || {{flagicon|YUG}} Sarajevo  || Giant Slalom\\n|-\\n| 4 December 1987 || {{flagicon|FRA}} Val-d\\'Isère || Downhill\\n|-\\n| 16 January 1988 || {{flagicon|SUI}}  [[Zinal]] || Downhill\\n|-\\n| 15 December 1988 || {{flagicon|AUT}}  [[Altenmarkt im Pongau|Altenmarkt]] || Downhill\\n|-\\n| 19 January 1989 || {{flagicon|FRA}}  [[Tignes]] || Downhill\\n|-\\n| 4 March 1989 || {{flagicon|Japan}} Furano || Giant Slalom\\n|-\\n| 9 December 1989 || {{flagicon|USA}}  [[Steamboat Springs, Colorado|Steamboat Springs]] || Downhill\\n|-\\n| 13 January 1990 || {{flagicon|AUT}}  [[Haus im Ennstal|Haus]] || Downhill\\n|}\\n\\n==World Championships results==\\n{| class=\"wikitable\" width=50% style=\"font-size:100%; text-align:center;\"\\n|-\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=40% | Edition\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Downhill\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Super-G\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Giant slalom\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Combined\\n|-\\n|align=left|{{flagicon|AUT}} [[1982 Alpine Skiing World Championships|1982 Schladming]] ||12||-||-||11\\n|-\\n|align=left|{{flagicon|ITA}} [[1985 Alpine Skiing World Championships|1985 Bormio]] ||6||-||8|| -\\n|-\\n|align=left|{{flagicon|SUI|civil}} [[1987 Alpine Skiing World Championships|1987 Crans-Montana]]||bgcolor=gold|1||bgcolor=gold|1||bgcolor=cc9966|3||-\\n|-\\n|align=left|{{flagicon|USA}} [[1989 Alpine Ski World Championships|1989 Vail]]||bgcolor=gold|1||4||4||-\\n|}\\n\\n==Olympic results==\\n{| class=\"wikitable\" width=50% style=\"font-size:100%; text-align:center;\"\\n|-\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=40% | Edition\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Downhill\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Super-G\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Giant slalom\\n! scope=\"col\" style=\"color:white; background-color:#369;\" width=\"20%\"| Combined\\n|-\\n|align=left|{{flagicon|YUG}} [[Alpine skiing at the 1984 Winter Olympics|1984 Sarajevo]]||bgcolor=silver|2||-||-||-\\n|-\\n|align=left|{{flagicon|CAN}} [[Alpine skiing at the 1988 Winter Olympics|1988 Calgary]]||4||6||bgcolor=cc9966|3||bgcolor=cc9966|3\\n|}\\n\\n==See also==\\n*[[List of FIS Alpine Ski World Cup women\\'s race winners]]\\n\\n==References==\\n{{reflist}}\\n\\n==External links==\\n* {{sports links}}\\n* {{Ski-DB}}\\n\\n{{Navboxes\\n| title=Related\\n| list1=\\n{{s-start}}\\n{{s-ach|aw}}\\n{{succession box\\n| before = {{flagicon|SUI}} [[Michela Figini]]\\n| title = [[Swiss Sportspersonality of the year|Swiss Sportswoman of the Year]]\\n| years = 1986–1987\\n| after = {{flagicon|SUI}} [[Vreni Schneider]]\\n}}\\n{{s-end}}\\n{{Footer World Champions Downhill Women}}\\n{{Footer World Champions Super-G Women}}\\n{{Footer World Cup Champions Women}}\\n{{Footer Giant Slalom World Cup Winners Women}}\\n{{Footer Super-G World Cup Winners Women}}\\n{{Footer Downhill World Cup Winners Women}}\\n{{Footer Alpine combination World Cup Winners Women}}\\n{{Authority control}}\\n}}\\n\\n{{DEFAULTSORT:Walliser, Maria}}\\n[[Category:1963 births]]\\n[[Category:Living people]]\\n[[Category:Swiss female alpine skiers]]\\n[[Category:Alpine skiers at the 1984 Winter Olympics]]\\n[[Category:Alpine skiers at the 1988 Winter Olympics]]\\n[[Category:Olympic alpine skiers for Switzerland]]\\n[[Category:Olympic silver medalists for Switzerland]]\\n[[Category:Olympic bronze medalists for Switzerland]]\\n[[Category:Olympic medalists in alpine skiing]]\\n[[Category:FIS Alpine Ski World Cup champions]]\\n[[Category:Medalists at the 1984 Winter Olympics]]\\n[[Category:Medalists at the 1988 Winter Olympics]]\\n[[Category:20th-century Swiss women]]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1653f1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ' Hanni Wenzel',\n",
       " 'image': ' Hanni Wenzel.png',\n",
       " 'image_size': ' ',\n",
       " 'caption': '  ',\n",
       " 'disciplines': ' [[Giant slalom|Giant Slalom]], [[Slalom skiing|Slalom]],<br />[[Alpine skiing combined|Combined]], [[Downhill (ski competition)|Downhill]],<br>[[Super-G|Super G]]',\n",
       " 'club': ' ',\n",
       " 'skis': ' ',\n",
       " 'boots': ' ',\n",
       " 'bindings': ' ',\n",
       " 'sponsor': ' ',\n",
       " 'birth_date': ' {{Birth date and age|1956|12|14|df=y}}',\n",
       " 'birth_place': ' [[Straubing]], [[Bavaria]],<br>[[West Germany]]',\n",
       " 'death_date': ' ',\n",
       " 'death_place': ' ',\n",
       " 'height': ' 1.65 m',\n",
       " 'weight': ' ',\n",
       " 'wcdebut': ' 1 March 1972 (age 15)',\n",
       " 'retired': ' March 1984  (age 27)',\n",
       " 'website': ' [http://www.wwp-group.com/en wwp-group.com]',\n",
       " 'olympicteams': ' 2 – ([[Alpine skiing at the 1976 Winter Olympics|1976]], [[Alpine skiing at the 1984 Winter Olympics|1980]])',\n",
       " 'olympicmedals': ' 4'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26fd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeline_keys = ['birth_date', 'medaltemplates', 'yearsactive', 'rating', 'peakrating', 'ranking', 'peakranking', 'title',\n",
    "#                  'worldchampion', 'womensworldchampion ']\n",
    "# final_timeline_keys = ['medaltemplates', 'yearsactive', 'rating', 'peakrating', 'ranking', 'peakranking', 'title',\n",
    "#                  'worldchampion', 'womensworldchampion ']\n",
    "timeline_keys = ['birth_date', 'medaltemplates', 'years', 'clubs', 'nationalteams', 'nationalyears']\n",
    "\n",
    "final_timeline_keys = ['medaltemplates', 'clubs', 'years', 'nationalteams', 'nationalyears']\n",
    "\n",
    "timeline = {}\n",
    "for key in timeline_keys:\n",
    "    try:\n",
    "        timeline[key] = raw_dict[key]\n",
    "    except:\n",
    "        pass\n",
    "# medal_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1c8f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_timeline = {}\n",
    "# try:\n",
    "#     final_timeline['date_of_highest_ranking'] = timeline['date_of_highest_ranking']\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     final_timeline['date_of_current_ranking'] = timeline['date_of_current_ranking']\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     final_timeline['turnedpro'] = [timeline['turnedpro']] \n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     lst = [re.findall(\"\\d\\d\\d\\d\", ele) for ele in [json_dict[\"years_active\"]] if re.findall(\"\\d\\d\\d\\d\", ele)]\n",
    "#     lst = [item for sublist in lst for item in sublist]\n",
    "#     final_timeline['years_active'] = list(set(lst))\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     lst = [re.findall(\"\\d\\d\\d\\d\", ele) for ele in json_dict[\"medaltemplates\"] if re.findall(\"\\d\\d\\d\\d\", ele)]\n",
    "#     lst = [item for sublist in lst for item in sublist]\n",
    "#     final_timeline['medaltemplates'] = list(set(lst))\n",
    "# except:\n",
    "#     pass\n",
    "# for key in raw_dict.keys():\n",
    "try:\n",
    "    lst = [re.findall(\"\\d\\d\\d\\d\", ele) for ele in raw_dict[key] if re.findall(\"\\d\\d\\d\\d\", ele)]\n",
    "    lst = [item for sublist in lst for item in sublist]\n",
    "    final_timeline[key] = list(set(lst))\n",
    "    if (final_timeline[key] == []):\n",
    "        lst = re.findall(\"\\d\\d\\d\\d\", raw_dict[key])\n",
    "        final_timeline[key] = list(set(lst))\n",
    "except:\n",
    "    pass\n",
    "# for key in raw_dict.keys():\n",
    "#     if \"year\" in key:\n",
    "#         try:\n",
    "#             lst = [re.findall(\"\\d\\d\\d\\d\", ele) for ele in raw_dict[key] if re.findall(\"\\d\\d\\d\\d\", ele)]\n",
    "#             lst = [item for sublist in lst for item in sublist]\n",
    "#             final_timeline[key] = list(set(lst))\n",
    "#             if (final_timeline[key] == []):\n",
    "#                 lst = re.findall(\"\\d\\d\\d\\d\", raw_dict[key])\n",
    "#                 final_timeline[key] = list(set(lst))\n",
    "#         except:\n",
    "#             pass\n",
    "# try:\n",
    "#     lst = [re.findall(\"\\d\\d\\d\\d\", ele) for ele in json_dict[\"WorldOpenResult\"] if re.findall(\"\\d\\d\\d\\d\", ele)]\n",
    "#     lst = [item for sublist in lst for item in sublist]\n",
    "#     final_timeline['WorldOpenResult'] = list(set(lst))\n",
    "# except:\n",
    "#     pass\n",
    "final_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6953418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022',\n",
       " '2010',\n",
       " '2018',\n",
       " '2021',\n",
       " '2012',\n",
       " '2014',\n",
       " '2020',\n",
       " '2016',\n",
       " '2006',\n",
       " '2019']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelines = re.findall(\"\\d\\d\\d\\d\", infobox2)\n",
    "final_timelines = []\n",
    "for ele in timelines:\n",
    "    if (int(ele) <= 2023) and (int(ele) >= 2000):\n",
    "        final_timelines.append(ele)\n",
    "        \n",
    "list(set(final_timelines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dac4b3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_edit_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27152/343493742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatei\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'000000'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatei\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'000000'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mget_edit_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_edit_history' is not defined"
     ]
    }
   ],
   "source": [
    "links = dict()\n",
    "links[page_title] = []\n",
    "for ele in final_timelines:\n",
    "    datei = dateparser.parse(ele)\n",
    "    start = datei.replace(month=1, day = 1).strftime(\"%Y%m%d\") + '000000'\n",
    "    end = datei.replace(month=12, day = 31).strftime(\"%Y%m%d\") + '000000'\n",
    "    links[page_title]  = links[page_title] + get_edit_history(page_title, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f171df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser\n",
    "links = dict()\n",
    "links[page_title] = []\n",
    "for key in final_timeline:\n",
    "    try:\n",
    "        date = dateparser.parse(final_timeline[key])\n",
    "        try:\n",
    "            if date.month == 1:\n",
    "                start = date.replace(month=12, year = date.year-1).strftime(\"%Y%m%d\") + '000000'\n",
    "            else:\n",
    "                start  = date.replace(month=date.month - 1).strftime(\"%Y%m%d\") + '000000'\n",
    "        except:\n",
    "            start  = date.replace(month=1).strftime(\"%Y%m%d\") + '000000'\n",
    "        try:\n",
    "            if date.month == 12:\n",
    "                end = date.replace(month=1, year = date.year+1).strftime(\"%Y%m%d\") + '000000'\n",
    "            else:\n",
    "                end = date.replace(month=date.month + 1).strftime(\"%Y%m%d\") + '000000'\n",
    "        except:\n",
    "            end = date.replace(month=12).strftime(\"%Y%m%d\") + '000000'\n",
    "    except:\n",
    "        try:\n",
    "            dates = [dateparser.parse(ele) for ele in final_timeline[key]]\n",
    "            start = []\n",
    "            end = []\n",
    "            for date in dates:\n",
    "                starti = date.replace(month=1).strftime(\"%Y%m%d\") + '000000'\n",
    "                endi = date.replace(month=12).strftime(\"%Y%m%d\") + '000000'\n",
    "                start.append(starti)\n",
    "                end.append(endi)\n",
    "        except:\n",
    "            pass\n",
    "#     print(\"Key: \", key)\n",
    "    print(\"Start: \", start)\n",
    "    print(\"End: \", end)\n",
    "#     try:\n",
    "#         links[page_title]  = links[page_title] + get_edit_history(page_title, start, end)\n",
    "#     except:\n",
    "#         try:\n",
    "#             for i in range(len(start)):\n",
    "#                 links[page_title]  = links[page_title] + get_edit_history(page_title, start[i], end[i])\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "# links[page_title] = [d for i, d in enumerate(links[page_title]) if d not in links[page_title][:i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d50ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d07d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(medal_templates[3].get(2).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw_dict['medaltemplates']\n",
    "medals = {}\n",
    "wikicode = parse(text)\n",
    "medal_templates = wikicode.filter_templates()\n",
    "\n",
    "for template in medal_templates:\n",
    "    if template.name.matches(\"MedalSport\"):\n",
    "        medals[\"sport\"] = clean_square(template.get(1).value.strip())\n",
    "    elif template.name.matches(\"MedalCountry\"):\n",
    "        medals[\"country\"] = clean_square(template.get(1).value.strip())\n",
    "    elif template.name.matches(\"MedalCompetition\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        if competition not in medals:\n",
    "            medals[competition] = {}\n",
    "    elif template.name.matches(\"MedalGold\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        if event not in medals[competition]:\n",
    "            medals[competition][event] = {}\n",
    "        medals[competition][event][\"gold\"] = year_event\n",
    "    elif template.name.matches(\"MedalSilver\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        if event not in medals[competition]:\n",
    "            medals[competition][event] = {}\n",
    "        medals[competition][event][\"silver\"] = year_event\n",
    "    elif template.name.matches(\"MedalBronze\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        if event not in medals[competition]:\n",
    "            medals[competition][event] = {}\n",
    "        medals[competition][event][\"bronze\"] = year_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a8818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(medal_templates[3].get(6).value.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_templates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw_dict['medaltemplates']\n",
    "wikicode = parse(value)\n",
    "medal_templates = wikicode.filter_templates()\n",
    "\n",
    "for template in medal_templates:\n",
    "    if template.name.matches(\"MedalSport\"):\n",
    "        global_lst.append(\"Sport: \"+clean(template.get(1).value.strip()))\n",
    "    elif template.name.matches(\"MedalCountry\"):\n",
    "        global_lst.append(\"Country: \"+clean_square(template.get(1).value.strip()))\n",
    "    elif template.name.matches(\"MedalCompetition\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        global_lst.append(\"Competition: \"+competition)\n",
    "    elif template.name.matches(\"MedalGold\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        global_lst.append('Gold Medal: '+competition+' '+year_event + ' ' + event)\n",
    "    elif template.name.matches(\"MedalSilver\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        global_lst.append('Silver Medal: '+competition+' '+year_event + ' ' + event)\n",
    "    elif template.name.matches(\"MedalBronze\"):\n",
    "        competition = clean_square(template.get(1).value.strip())\n",
    "        year_event = clean_square(template.get(2).value.strip())\n",
    "        event = clean_square(template.get(3).value.strip())\n",
    "        global_lst.append('Bronze Medal: '+competition+' '+year_event + ' ' + event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17758a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw_dict['birth_date']\n",
    "result = remove_refs(text)\n",
    "print(result)\n",
    "result = remove_pixel_info(result)\n",
    "print(result)\n",
    "result = remove_html(result) \n",
    "print(result)\n",
    "result = replace_special(result)\n",
    "print(result)\n",
    "lst = extract_text_between_braces(result)\n",
    "lst_alt = []\n",
    "for ele in lst:\n",
    "    if '|' in ele:\n",
    "        result = result.replace(ele, ele.split('|')[1])\n",
    "print(result)\n",
    "lst = extract_text_between_curly_braces(result)\n",
    "lst_alt = []\n",
    "for ele in lst:\n",
    "    if ('|' in ele) and ('hlist' not in ele) and ('birth' not in ele):\n",
    "        result = result.replace(ele, ele.split('|')[1])\n",
    "result = re.sub('[\\[\\]]+','',result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dict_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_edit_history(page_title, start_date, end_date):\n",
    "    # Initialize an empty list to store the revisions\n",
    "    revisions = []\n",
    "    \n",
    "    # Set the base URL for the API request\n",
    "    api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    # Set the parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"titles\": page_title,\n",
    "        \"rvstart\":start_date,\n",
    "        \"rvend\":end_date,\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvlimit\": \"500\",\n",
    "        \"rvdir\": \"newer\"\n",
    "    }\n",
    "    \n",
    "    # Set a flag to indicate whether there are more revisions to retrieve\n",
    "    more_revisions = True\n",
    "    \n",
    "    while more_revisions:\n",
    "        # Make the API request\n",
    "        response = requests.get(api_url, params=params)\n",
    "        \n",
    "        # Get the data from the response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract the revisions from the data\n",
    "        page_id = list(data[\"query\"][\"pages\"].keys())[0]\n",
    "        page_revisions = data[\"query\"][\"pages\"][page_id][\"revisions\"]\n",
    "        \n",
    "        # Add the revisions to the list\n",
    "        revisions.extend(page_revisions)\n",
    "        \n",
    "        # Check if there are more revisions to retrieve\n",
    "        if \"continue\" in data:\n",
    "            # Update the rvcontinue parameter for the next request\n",
    "            params[\"rvcontinue\"] = data[\"continue\"][\"rvcontinue\"]\n",
    "        else:\n",
    "            # Set the flag to False to stop the loop\n",
    "            more_revisions = False\n",
    "    \n",
    "    # Return the list of revisions\n",
    "    return revisions\n",
    "# get_edit_history(\"Natalie_Grainger\", start[1], end[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b6d617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Grand Tour (cycling)\n",
      "Grand Tours\n",
      " \n",
      "br\n",
      " :\n",
      "Tour de France\n",
      " :: 1 individual stage (\n",
      "2003 Tour de France\n",
      "2003\n",
      ") :\n",
      "Giro d'Italia\n",
      " :: 1 individual stage (\n",
      "2002 Giro d'Italia\n",
      "2002\n",
      ") :\n",
      "Vuelta a España\n",
      " :: 1 individual stage (\n",
      "2004 Vuelta a España\n",
      "2004\n",
      ") \n",
      "Race stage\n",
      "Stage races\n",
      " :\n",
      "Tour de Romandie\n",
      " (2003, 2004) :\n",
      "Dauphiné Libéré\n",
      " (2000) \n",
      "Classic cycle races\n",
      "Single-day races and Classics\n",
      " :\n",
      "nowrap\n",
      "United States National Road Race Championships\n",
      "National Road Race Championships\n",
      " (2008)\n",
      " :\n",
      "Liège–Bastogne–Liège\n",
      " (2003)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mwparserfromhell\n",
    "\n",
    "wikicode = \"\"\"\n",
    "'''[[Grand Tour (cycling)|Grand Tours]]''' <br/> :'''[[Tour de France]]''' :: 1 individual stage ([[2003 Tour de France|2003]]) :'''[[Giro d'Italia]]''' :: 1 individual stage ([[2002 Giro d'Italia|2002]]) :'''[[Vuelta a España]]''' :: 1 individual stage ([[2004 Vuelta a España|2004]]) '''[[Race stage|Stage races]]''' :[[Tour de Romandie]] (2003, 2004) :[[Dauphiné Libéré]] (2000) '''[[Classic cycle races|Single-day races and Classics]]''' :{{nowrap|[[United States National Road Race Championships|National Road Race Championships]] (2008)}} :[[Liège–Bastogne–Liège]] (2003)\n",
    "\"\"\"\n",
    "\n",
    "wikicode = mwparserfromhell.parse(wikicode)\n",
    "\n",
    "# Extracting the contents of each line\n",
    "for line in wikicode.filter_text():\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98ac2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City,Colors Reported,Shape Reported,State,Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ithaca,,TRIANGLE,NY,6/1/1930 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willingboro,,OTHER,NJ,6/30/1930 20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holyoke,,OVAL,CO,2/15/1931 14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene,,DISK,KS,6/1/1931 13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Worlds Fair,,LIGHT,NY,4/18/1933 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18236</th>\n",
       "      <td>Grant Park,,TRIANGLE,IL,12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>Spirit Lake,,DISK,IA,12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>Eagle River,,,WI,12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>Eagle River,RED,LIGHT,WI,12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>Ybor,,OVAL,FL,12/31/2000 23:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18241 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       City,Colors Reported,Shape Reported,State,Time\n",
       "0                  Ithaca,,TRIANGLE,NY,6/1/1930 22:00\n",
       "1               Willingboro,,OTHER,NJ,6/30/1930 20:00\n",
       "2                    Holyoke,,OVAL,CO,2/15/1931 14:00\n",
       "3                     Abilene,,DISK,KS,6/1/1931 13:00\n",
       "4      New York Worlds Fair,,LIGHT,NY,4/18/1933 19:00\n",
       "...                                               ...\n",
       "18236        Grant Park,,TRIANGLE,IL,12/31/2000 23:00\n",
       "18237           Spirit Lake,,DISK,IA,12/31/2000 23:00\n",
       "18238               Eagle River,,,WI,12/31/2000 23:45\n",
       "18239       Eagle River,RED,LIGHT,WI,12/31/2000 23:45\n",
       "18240                  Ybor,,OVAL,FL,12/31/2000 23:59\n",
       "\n",
       "[18241 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('http://bit.ly/uforeports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2383a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
